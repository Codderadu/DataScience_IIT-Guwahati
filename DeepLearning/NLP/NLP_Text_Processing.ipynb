{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81989c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/92/fb/d1f0605e1e8627226c6c96053fe1632e9a04a3fbcd8b5d715528cb95eb97/spacy-3.7.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Obtaining dependency information for spacy-legacy<3.1.0,>=3.0.11 from https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/71/46/af01a20ec368bd9cb49a1d2df15e3eca113bbf6952cc1f2a47f1c6801a7f/murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/c1/c3/dd044e6f62a3d317c461f6f0c153c6573ed13025752d779e514000c15dd2/cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.2.2 from https://files.pythonhosted.org/packages/de/a5/c242d57dc7a8afe677aa48ce370d84be3d04523cbb819c4a36b64f35155c/thinc-8.2.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Obtaining dependency information for typer<0.10.0,>=0.3.0 from https://files.pythonhosted.org/packages/62/39/82c9d3e10979851847361d922a373bdfef4091020da7f893acfaf07c0225/typer-0.9.4-py3-none-any.whl.metadata\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Obtaining dependency information for langcodes<4.0.0,>=3.2.0 from https://files.pythonhosted.org/packages/58/70/4058ab0ebb082b18d06888e711baed7f33354a5e0b363bb627586d8c323a/langcodes-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for language-data>=1.2 from https://files.pythonhosted.org/packages/12/5f/139464da89c49afcc8bb97ebad48818a535220ce01b1f24c61fb80dbe4d0/language_data-1.2.0-py3-none-any.whl.metadata\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\adina\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adina\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Obtaining dependency information for marisa-trie>=0.7.7 from https://files.pythonhosted.org/packages/3e/6d/ed921d88d596094aa8dd5749ab83a95b09f8f8f0b057cb6cac0d376ea398/marisa_trie-1.1.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading marisa_trie-1.1.1-cp311-cp311-win_amd64.whl.metadata (8.9 kB)\n",
      "Downloading spacy-3.7.4-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.1 MB 1.9 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.0/12.1 MB 1.9 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.1/12.1 MB 657.6 kB/s eta 0:00:19\n",
      "   ---------------------------------------- 0.1/12.1 MB 853.3 kB/s eta 0:00:14\n",
      "    --------------------------------------- 0.2/12.1 MB 958.4 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.3/12.1 MB 1.0 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.4/12.1 MB 1.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.5/12.1 MB 1.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.6/12.1 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/12.1 MB 1.7 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.9/12.1 MB 1.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.1/12.1 MB 1.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.2/12.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/12.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/12.1 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.7/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.9/12.1 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.0/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.0/12.1 MB 2.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.1 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.3/12.1 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.3/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.5/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.7/12.1 MB 2.1 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.8/12.1 MB 2.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.0/12.1 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.1/12.1 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.3/12.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.5/12.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.6/12.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.7/12.1 MB 2.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.9/12.1 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.2/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.4/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.5/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.6/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.7/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.8/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.9/12.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.1/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.4/12.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.4/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.5/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.6/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.6/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.7/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.8/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.8/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.9/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.0/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.1/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.3/12.1 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.5/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.7/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.9/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 2.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.2/12.1 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.5/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.6/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.7/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.7/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.8/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.0/12.1 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.1/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.3/12.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.9/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.5/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.6/12.1 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.9/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.4/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.6/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.7/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.1/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.7/12.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.0 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 122.9/182.0 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 182.0/182.0 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 112.6/479.7 kB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 286.7/479.7 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 409.6/479.7 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 479.7/479.7 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.3-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/6.6 MB 1.7 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.1/6.6 MB 1.4 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.4/6.6 MB 2.4 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.5/6.6 MB 2.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.5/6.6 MB 1.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.6/6.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.7/6.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.8/6.6 MB 2.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.9/6.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.9/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.9/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/6.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.1/6.6 MB 1.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.2/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.2/6.6 MB 1.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.2/6.6 MB 1.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.3/6.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.2/6.6 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 2.3/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.4/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.5/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 2.6/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.7/6.6 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.8/6.6 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.0/6.6 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.3/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.4/6.6 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.6/6.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.8/6.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.8/6.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.9/6.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.0/6.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 4.1/6.6 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.4/6.6 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.5/6.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.7/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.8/6.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.9/6.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.0/6.6 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.1/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.1/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.3/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.4/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.6/6.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.7/6.6 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.9/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.0/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.4/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.4 MB 2.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/5.4 MB 1.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.2/5.4 MB 1.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.3/5.4 MB 1.5 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.3/5.4 MB 1.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.4/5.4 MB 1.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.4/5.4 MB 1.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.4/5.4 MB 1.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.4/5.4 MB 1.1 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.5/5.4 MB 982.5 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 983.0 kB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.5/5.4 MB 964.2 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.6/5.4 MB 568.4 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 0.7/5.4 MB 628.1 kB/s eta 0:00:08\n",
      "   ------ --------------------------------- 0.8/5.4 MB 681.5 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.0/5.4 MB 823.2 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.0/5.4 MB 823.2 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.0/5.4 MB 823.2 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 1.5/5.4 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.7/5.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.7/5.4 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.8/5.4 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 1.9/5.4 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.0/5.4 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 2.0/5.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 2.2/5.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 2.3/5.4 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.4/5.4 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 2.5/5.4 MB 1.4 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 2.6/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.8/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.8/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.0/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.2/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.2/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.3/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.4/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 3.6/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.6/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.7/5.4 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 3.8/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 3.9/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 1.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 4.5/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.6/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.8/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.9/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.1/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.3/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading marisa_trie-1.1.1-cp311-cp311-win_amd64.whl (153 kB)\n",
      "   ---------------------------------------- 0.0/153.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 61.4/153.3 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 153.3/153.3 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, typer, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.1.1 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.4 wasabi-1.1.2 weasel-0.3.4\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7887dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8abc5b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>3975</td>\n",
       "      <td>116663</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Nov 01 21:02:24 +0000 2017</td>\n",
       "      <td>@British_Airways The staff in the counter issu...</td>\n",
       "      <td>3,97,73,978</td>\n",
       "      <td>3974.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>3977</td>\n",
       "      <td>British_Airways</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Nov 02 08:47:23 +0000 2017</td>\n",
       "      <td>@116663 contact telephone number. We'll look a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>3978</td>\n",
       "      <td>British_Airways</td>\n",
       "      <td>False</td>\n",
       "      <td>Thu Nov 02 08:46:39 +0000 2017</td>\n",
       "      <td>@116663 Hi Omar. Please can you DM more inform...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>3976</td>\n",
       "      <td>116663</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 16:33:33 +0000 2017</td>\n",
       "      <td>@British_Airways i hope you can help me, becus...</td>\n",
       "      <td>3974</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>3979</td>\n",
       "      <td>British_Airways</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 23:12:32 +0000 2017</td>\n",
       "      <td>@116664 We're so sorry to hear this, Tracey. H...</td>\n",
       "      <td>3980</td>\n",
       "      <td>3981.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id        author_id  inbound                      created_at  \\\n",
       "0            1       sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1            2           115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2            3           115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3            4       sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4            5           115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "...        ...              ...      ...                             ...   \n",
       "2995      3975           116663     True  Wed Nov 01 21:02:24 +0000 2017   \n",
       "2996      3977  British_Airways    False  Thu Nov 02 08:47:23 +0000 2017   \n",
       "2997      3978  British_Airways    False  Thu Nov 02 08:46:39 +0000 2017   \n",
       "2998      3976           116663     True  Tue Oct 31 16:33:33 +0000 2017   \n",
       "2999      3979  British_Airways    False  Tue Oct 31 23:12:32 +0000 2017   \n",
       "\n",
       "                                                   text response_tweet_id  \\\n",
       "0     @115712 I understand. I would like to assist y...                 2   \n",
       "1         @sprintcare and how do you propose we do that               NaN   \n",
       "2     @sprintcare I have sent several private messag...                 1   \n",
       "3     @115712 Please send us a Private Message so th...                 3   \n",
       "4                                    @sprintcare I did.                 4   \n",
       "...                                                 ...               ...   \n",
       "2995  @British_Airways The staff in the counter issu...       3,97,73,978   \n",
       "2996  @116663 contact telephone number. We'll look a...               NaN   \n",
       "2997  @116663 Hi Omar. Please can you DM more inform...               NaN   \n",
       "2998  @British_Airways i hope you can help me, becus...              3974   \n",
       "2999  @116664 We're so sorry to hear this, Tracey. H...              3980   \n",
       "\n",
       "      in_response_to_tweet_id  \n",
       "0                         3.0  \n",
       "1                         1.0  \n",
       "2                         4.0  \n",
       "3                         5.0  \n",
       "4                         6.0  \n",
       "...                       ...  \n",
       "2995                   3974.0  \n",
       "2996                   3975.0  \n",
       "2997                   3975.0  \n",
       "2998                      NaN  \n",
       "2999                   3981.0  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df=pd.read_csv(\"twcs_v1.csv\",nrows=3000)\n",
    "df=full_df[[\"text\"]]\n",
    "df[\"text\"]=df[\"text\"].astype(str);\n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff275c0f",
   "metadata": {},
   "source": [
    "##### Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d9112a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_lower\"]=df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70399d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \n",
       "0  @115712 i understand. i would like to assist y...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare i have sent several private messag...  \n",
       "3  @115712 please send us a private message so th...  \n",
       "4                                 @sprintcare i did.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473311a",
   "metadata": {},
   "source": [
    "#### Removal of Punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8371682",
   "metadata": {},
   "source": [
    "One another common text preprocessing technique is to remove the punctuations from the text data. This is again a text standardization process that will help to treat 'hurray' and 'hurray!' in the same way.\n",
    "\n",
    "We also need to carefully choose the list of punctuations to exclude depending on the use case. For example, the string.punctuation in python contains the following punctuation symbols\n",
    "\n",
    "!\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~`\n",
    "\n",
    "We can add or remove more punctuations as per our need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "925ec0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_TO_REMOVE=string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"custom function to remove the punctuation\"\n",
    "    return text.translate(str.maketrans('','',PUNCT_TO_REMOVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0953ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_to_punct\"]=df[\"text_lower\"].apply(lambda text:remove_punctuation(text));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b94bd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_to_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>115712 i understand i would like to assist you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>sprintcare i have sent several private message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>115712 please send us a private message so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>sprintcare i did</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_to_punct  \n",
       "0  115712 i understand i would like to assist you...  \n",
       "1       sprintcare and how do you propose we do that  \n",
       "2  sprintcare i have sent several private message...  \n",
       "3  115712 please send us a private message so tha...  \n",
       "4                                   sprintcare i did  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257383d",
   "metadata": {},
   "source": [
    "#### Removal of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad6018",
   "metadata": {},
   "source": [
    "Stopwords are commonly occuring words in a language like 'the', 'a' and so on. They can be removed from the text most of the times, as they don't provide valuable information for downstream analysis. In cases like Part of Speech tagging, we should not remove them as provide very valuable information about the POS.\n",
    "\n",
    "These stopword lists are already compiled for different languages and we can safely use them. For example, the stopword list for english language from the nltk package can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fd45d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0be16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    \"function of removing stop words\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in stopWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d26becd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"remove_stopwords\"]=df[\"text_to_punct\"].apply(lambda text:remove_stopword(text));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f32c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_to_punct</th>\n",
       "      <th>remove_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>115712 i understand i would like to assist you...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>sprintcare i have sent several private message...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>115712 please send us a private message so tha...</td>\n",
       "      <td>115712 please send us private message assist c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>sprintcare i did</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_to_punct  \\\n",
       "0  115712 i understand i would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare i have sent several private message...   \n",
       "3  115712 please send us a private message so tha...   \n",
       "4                                   sprintcare i did   \n",
       "\n",
       "                                    remove_stopwords  \n",
       "0  115712 understand would like assist would need...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private messages one r...  \n",
       "3  115712 please send us private message assist c...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87d6d5",
   "metadata": {},
   "source": [
    "#### Removal of Frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031d916b",
   "metadata": {},
   "source": [
    "In the previos preprocessing step, we removed the stopwords based on language information. But say, if we have a domain specific corpus, we might also have some frequent words which are of not so much importance to us.\n",
    "\n",
    "So this step is to remove the frequent words in the given corpus. If we use something like tfidf, this is automatically taken care of.\n",
    "\n",
    "Let us get the most common words and then remove them in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21658405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt=Counter()\n",
    "for text in df[\"remove_stopwords\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word]+=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45b6823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('us', 461),\n",
       " ('please', 388),\n",
       " ('dm', 303),\n",
       " ('help', 302),\n",
       " ('thanks', 230),\n",
       " ('hi', 205),\n",
       " ('get', 169),\n",
       " ('know', 158),\n",
       " ('like', 152),\n",
       " ('sorry', 152)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5c5cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQWORDS=set([w for (w,wc) in cnt.most_common(10)])\n",
    "def remove_freq_word(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de0cd49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reomve_freqword\"]=df[\"remove_stopwords\"].apply(lambda text:remove_freq_word(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f79163a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_to_punct</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>reomve_freqword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>115712 i understand i would like to assist you...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>sprintcare i have sent several private message...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>115712 please send us a private message so tha...</td>\n",
       "      <td>115712 please send us private message assist c...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>sprintcare i did</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_to_punct  \\\n",
       "0  115712 i understand i would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare i have sent several private message...   \n",
       "3  115712 please send us a private message so tha...   \n",
       "4                                   sprintcare i did   \n",
       "\n",
       "                                    remove_stopwords  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 please send us private message assist c...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                     reomve_freqword  \n",
       "0  115712 understand would assist would need priv...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private messages one r...  \n",
       "3  115712 send private message assist click â€˜mess...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6822e8",
   "metadata": {},
   "source": [
    "##### Removal of Rare words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f6a38",
   "metadata": {},
   "source": [
    "This is very similar to previous preprocessing step but we will remove the rare words from the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a1290b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rare_words=10\n",
    "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
    "def remove_rare_word(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dbf9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"remove_rarewords\"]=df[\"reomve_freqword\"].apply(lambda text:remove_rare_word(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca9ab919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_to_punct</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>reomve_freqword</th>\n",
       "      <th>remove_rarewords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>115712 i understand i would like to assist you...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>sprintcare i have sent several private message...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>115712 please send us a private message so tha...</td>\n",
       "      <td>115712 please send us private message assist c...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>sprintcare i did</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_to_punct  \\\n",
       "0  115712 i understand i would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare i have sent several private message...   \n",
       "3  115712 please send us a private message so tha...   \n",
       "4                                   sprintcare i did   \n",
       "\n",
       "                                    remove_stopwords  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 please send us private message assist c...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                     reomve_freqword  \\\n",
       "0  115712 understand would assist would need priv...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send private message assist click â€˜mess...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                    remove_rarewords  \n",
       "0  115712 understand would assist would need priv...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private messages one r...  \n",
       "3  115712 send private message assist click â€˜mess...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af0b3e",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82bbc2",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form\n",
    "\n",
    "For example, if there are two words in the corpus walks and walking, then stemming will stem the suffix to make them walk. But say in another example, we have two words console and consoling, the stemmer will remove the suffix and make them consol which is not a proper english word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50ae654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e2b08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_stemmed\"]=df[\"remove_rarewords\"].apply(lambda text:stem_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4bd1ac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_to_punct</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>reomve_freqword</th>\n",
       "      <th>remove_rarewords</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>115712 i understand i would like to assist you...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcar propos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>sprintcare i have sent several private message...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcar sent sever privat messag one respond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>115712 please send us a private message so tha...</td>\n",
       "      <td>115712 please send us private message assist c...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "      <td>115712 send privat messag assist click â€˜messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>sprintcare i did</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_to_punct  \\\n",
       "0  115712 i understand i would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare i have sent several private message...   \n",
       "3  115712 please send us a private message so tha...   \n",
       "4                                   sprintcare i did   \n",
       "\n",
       "                                    remove_stopwords  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 please send us private message assist c...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                     reomve_freqword  \\\n",
       "0  115712 understand would assist would need priv...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send private message assist click â€˜mess...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                    remove_rarewords  \\\n",
       "0  115712 understand would assist would need priv...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send private message assist click â€˜mess...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  115712 understand would assist would need priv...  \n",
       "1                                   sprintcar propos  \n",
       "2  sprintcar sent sever privat messag one respond...  \n",
       "3  115712 send privat messag assist click â€˜messag...  \n",
       "4                                          sprintcar  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e9556",
   "metadata": {},
   "source": [
    "We can see that words like private and propose have their e at the end chopped off due to stemming. This is not intented. What can we do fort hat? We can use Lemmatization in such cases.\n",
    "\n",
    "Also this porter stemmer is for English language. If we are working with other languages, we can use snowball stemmer. The supported languages for snowball stemmer are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69f079a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0232b4b",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473a786",
   "metadata": {},
   "source": [
    "Lemmatization is similar to stemming in reducing inflected words to their word stem but differs in the way that it makes sure the root word (also called as lemma) belongs to the language.\n",
    "\n",
    "As a result, this one is generally slower than stemming process. So depending on the speed requirement, we can choose to use either stemming or lemmatization.\n",
    "\n",
    "Let us use the WordNetLemmatizer in nltk to lemmatize our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91a51631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f568595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_lemmatized\"]=df[\"remove_rarewords\"].apply(lambda text:lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ede506a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_to_punct</th>\n",
       "      <th>remove_stopwords</th>\n",
       "      <th>reomve_freqword</th>\n",
       "      <th>remove_rarewords</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>115712 i understand i would like to assist you...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "      <td>115712 understand would assist would need priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcar propos</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "      <td>sprintcare i have sent several private message...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>sprintcar sent sever privat messag one respond...</td>\n",
       "      <td>sprintcare sent several private message one re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "      <td>115712 please send us a private message so tha...</td>\n",
       "      <td>115712 please send us private message assist c...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "      <td>115712 send privat messag assist click â€˜messag...</td>\n",
       "      <td>115712 send private message assist click â€˜mess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "      <td>sprintcare i did</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>sprintcar</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare i have sent several private messag...   \n",
       "3  @115712 please send us a private message so th...   \n",
       "4                                 @sprintcare i did.   \n",
       "\n",
       "                                       text_to_punct  \\\n",
       "0  115712 i understand i would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare i have sent several private message...   \n",
       "3  115712 please send us a private message so tha...   \n",
       "4                                   sprintcare i did   \n",
       "\n",
       "                                    remove_stopwords  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 please send us private message assist c...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                     reomve_freqword  \\\n",
       "0  115712 understand would assist would need priv...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send private message assist click â€˜mess...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                    remove_rarewords  \\\n",
       "0  115712 understand would assist would need priv...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send private message assist click â€˜mess...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  115712 understand would assist would need priv...   \n",
       "1                                   sprintcar propos   \n",
       "2  sprintcar sent sever privat messag one respond...   \n",
       "3  115712 send privat messag assist click â€˜messag...   \n",
       "4                                          sprintcar   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  115712 understand would assist would need priv...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private message one re...  \n",
       "3  115712 send private message assist click â€˜mess...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859100bd",
   "metadata": {},
   "source": [
    "### Removal of Emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bcdc5",
   "metadata": {},
   "source": [
    "With more and more usage of social media platforms, there is an explosion in the usage of emojis in our day to day life as well. Probably we might need to remove these emojis for some of our textual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44abde5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
